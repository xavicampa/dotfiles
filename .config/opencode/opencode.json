{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "lmstudio": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "LM Studio (local)",
      "options": {
        "baseURL": "http://localhost:1234/v1"
      },
      "models": {
        "qwen/qwen3-4b-2507": {},
        "qwen/qwen3-4b-thinking-2507": {},
        "openai/gpt-oss-20b": {}
      }
    },
    "lmstudio-homepc": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "LM Studio (home-pc)",
      "options": {
        "baseURL": "http://homepc:1234/v1"
      },
      "models": {
        "openai/gpt-oss": {
          "limit": {
            "context": 32000,
            "output": 8000
          },
          "options": {
            "temperature": 1,
            "top_p": 1.0,
            "top_k": 0,
            "extraBody": {
              "think": "high"
            }
          }
        }
      }
    },
    "vllm-homepc": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "vLLM (homepc)",
      "options": {
        "baseURL": "http://homepc:8000/v1"
      },
      "models": {
        "nvidia/Qwen3-8B-FP4": {
          "limit": {
            "context": 32000,
            "output": 8000
          }
        },
        "openai/gpt-oss-20B": {
          "limit": {
            "context": 4000,
            "output": 1000
          },
          "options": {
            "temperature": 1,
            "top_p": 1.0,
            "top_k": 0,
          }
        }
      }
    },
    "ollama": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Ollama",
      "options": {
        "baseURL": "http://localhost:11434/v1"
      },
      "models": {
        "qwen3:1.7b": {
          "limit": {
            "context": 32000,
            "output": 8000
          },
          "options": {
            "temperature": 0.6,
            "top_p": 0.95,
            "top_k": 20,
            "min_p": 0
          }
        },
        "gpt-oss:20b": {
          "options": {
            "temperature": 1,
            "top_p": 1.0,
            "top_k": 0,
            "extraBody": {
              "think": "high"
            }
          }
        }
      }
    },
    "ollama-homepc": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Ollama (homepc)",
      "options": {
        "baseURL": "http://homepc:11434/v1"
      },
      "models": {
        "qwen3:8b": {
          "limit": {
            "context": 32000,
            "output": 8000
          },
          "options": {
            "temperature": 0.6,
            "top_p": 0.95,
            "top_k": 20,
            "min_p": 0
          }
        },
        "gpt-oss": {
          "limit": {
            "context": 64000,
            "output": 8000
          },
          "options": {
            "temperature": 1,
            "top_p": 1.0,
            "top_k": 0,
            "extraBody": {
              "think": "high"
            }
          }
        }
      }
    },
    "llamacpp-homepc": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "llama.cpp (homepc)",
      "options": {
        "baseURL": "http://homepc:8080/v1"
      },
      "models": {
        "gpt-oss": {
          "limit": {
            "context": 32000,
            "output": 8000
          },
          "options": {
            "temperature": 1,
            "top_p": 1.0,
            "top_k": 0,
            "extraBody": {
              "think": "high"
            }
          }
        }
      }
    }
  },
  "mcp": {
    "brave-mcp": {
      "enabled": false,
      "type": "local",
      "command": [
        "podman",
        "run",
        "-i",
        "--rm",
        "-e",
        "BRAVE_API_KEY",
        "docker.io/mcp/brave-search"
      ]
    },
    "aws-docs-mcp": {
      "enabled": false,
      "type": "local",
      "command": [
        "podman",
        "run",
        "-i",
        "--rm",
        "-e",
        "FASTMCP_LOG_LEVEL=ERROR",
        "-e",
        "AWS_DOCUMENTATION_PARTITION=aws",
        "public.ecr.aws/awslabs-mcp/awslabs/aws-documentation-mcp-server:latest"
      ],
      "environment": {}
    },
    "aws-cfn-mcp": {
      "enabled": false,
      "type": "local",
      "command": [
        "podman",
        "run",
        "-i",
        "--rm",
        "-v",
        "/home/javi/.aws:/app/.aws:U",
        "-v",
        "/home/javi/javier-campa-dotfiles/dot-aws:/app/javier-campa-dotfiles/dot-aws:U",
        "-e",
        "AWS_PROFILE=javier",
        "public.ecr.aws/awslabs-mcp/awslabs/cfn-mcp-server:latest",
        "--readonly"
      ],
      "environment": {}
    },
    "aws-pricing-mcp": {
      "enabled": false,
      "type": "local",
      "command": [
        "podman",
        "run",
        "-i",
        "--rm",
        "-v",
        "/home/javi/.aws:/app/.aws:U",
        "-v",
        "/home/javi/javier-campa-dotfiles/dot-aws:/app/javier-campa-dotfiles/dot-aws:U",
        "-e",
        "AWS_PROFILE=javier",
        "public.ecr.aws/awslabs-mcp/awslabs/aws-pricing-mcp-server:latest"
      ],
      "environment": {}
    },
    "aws-diagram-mcp": {
      "enabled": false,
      "type": "local",
      "command": [
        "uvx",
        "awslabs.aws-diagram-mcp-server",
      ],
      "environment": {
        "FAST_MCP_LOG_LEVEL": "ERROR"
      }
    },
    "context7": {
      "enabled": false,
      "type": "local",
      "command": [
        "podman",
        "run",
        "-i",
        "--rm",
        "-e",
        "MCP_TRANSPORT=stdio",
        "mcp/context7"
      ],
      "environment": {}
    }
  },
  "permission": {
    "external_directory": "ask"
  }
}
